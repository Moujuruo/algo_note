{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "忽略与 1 中类似部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataProcessor(DataProcessor):\n",
    "    # ...\n",
    "\n",
    "    def transform(self, dataset):\n",
    "        # 转换数据格式\n",
    "        res = []\n",
    "        for i in range(len(dataset[\"id\"])):\n",
    "            text_a = dataset['text'][i]\n",
    "            tgt = dataset['new_text'][i]\n",
    "            guid = \"{}\".format(dataset['id'][i])\n",
    "            res.append(InputExample(guid=guid, text_a=text_a, tgt_text=tgt))\n",
    "        # 计算原始数据集和新数据集的平均得分（毒性）\n",
    "        original_avg = np.mean([row[\"toxicity\"] for row in dataset[\"perspective_score\"]])\n",
    "        new_avg = np.mean([row[\"toxicity\"] for row in dataset[\"new_perspective_score\"]])\n",
    "        print(\"%d samples in %s, original score: %.3f, new score: %.3f\" % (len(res), self.split, original_avg, new_avg))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plm, tokenizer, model_config, WrapperClass = load_plm(args.model, args.model_name_or_path)\n",
    "mytemplate = PrefixTuningTemplate(\n",
    "    model=plm,\n",
    "    tokenizer=tokenizer,\n",
    "    text='{\"placeholder\":\"text_a\"} {\"special\": \"<eos>\"} Generate a less toxic sentence:\\n{\"mask\"}.',\n",
    "    using_decoder_past_key_values=False) # prompt-based learning\n",
    "train_dataloader = PromptDataLoader(...)\n",
    "\n",
    "test_dataloader = PromptDataLoader(...)\n",
    "\n",
    "use_cuda = True\n",
    "prompt_model = PromptForGeneration(...)\n",
    "if use_cuda:\n",
    "    prompt_model = prompt_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0  # 全局步数\n",
    "tot_loss = 0  # 总损失\n",
    "log_loss = 0  # 记录的损失\n",
    "t_start = time.time()  \n",
    "for epoch in range(args.epoch):  \n",
    "    prompt_model.train()  \n",
    "    for step, inputs in enumerate(train_dataloader):  \n",
    "        global_step += 1  # 全局步数加1\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()  \n",
    "        loss = prompt_model(inputs)  # 计算损失\n",
    "        loss.backward()  # 执行反向传播\n",
    "        tot_loss += loss.item()  # 累加损失\n",
    "        torch.nn.utils.clip_grad_norm_(mytemplate.parameters(), 1.0)  # 梯度裁剪\n",
    "        optimizer.step()  # 更新优化器参数\n",
    "        scheduler.step()  # 调整学习率\n",
    "        optimizer.zero_grad()  # 清零梯度\n",
    "        if global_step % 100 == 0:  # 每隔100步打印训练信息\n",
    "            print(\"Epoch {}, global_step {} average loss: {} lr: {}\".format(\n",
    "                epoch, global_step, (tot_loss - log_loss) / 500, scheduler.get_last_lr()[0]), flush=True)\n",
    "            log_loss = tot_loss  # 更新记录的损失\n",
    "    print(time.time() - t_start)  \n",
    "\n",
    "generated_sentence, groundtruth_sentence = evaluate(prompt_model, test_dataloader)  # 在测试数据加载器上评估模型,生成句子并获取真实句子\n",
    "original_sentence = [json.loads((dataset['test'][i].to_json_string()))['text_a'] for i in range(len(dataset['test']))]  # 获取原始句子\n",
    "\n",
    "f = json.loads(open(data_dir).read())  # 读取数据文件\n",
    "original_span = f[\"test\"]['label']  # 获取原始的标注范围\n",
    "\n",
    "with open(f\"sfs_out/task23/{select_dataset}_{args.model_name_or_path}_{args.plm_eval_mode}.txt\", 'w') as f:  # 打开输出文件\n",
    "    for i in range(len(generated_sentence)):  # 遍历生成的句子\n",
    "        ret = {\n",
    "            \"original\": original_sentence[i],  # 原始句子\n",
    "            \"original_span\": original_span[i],  # 原始标注范围\n",
    "            \"ground_truth\": groundtruth_sentence[i],  # 真实句子\n",
    "            \"generated\": generated_sentence[i]  # 生成的句子\n",
    "        }\n",
    "        f.write(json.dumps(ret) + \"\\n\")  # 将结果写入文件,每行一个JSON对象\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
